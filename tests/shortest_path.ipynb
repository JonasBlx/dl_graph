{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           Feature_X  \\\n",
      "0  [0, 80, 37, 13, 93, 49, 56, 53, 38, 50, 15, 5,...   \n",
      "1  [0, 55, 46, 91, 69, 33, 47, 99, 98, 61, 0, 57,...   \n",
      "2  [0, 52, 17, 69, 43, 39, 63, 77, 18, 0, 80, 99,...   \n",
      "3  [0, 65, 28, 86, 65, 41, 32, 13, 88, 0, 77, 82,...   \n",
      "4  [0, 31, 42, 92, 25, 35, 1, 10, 21, 52, 78, 0, ...   \n",
      "\n",
      "                                Target_y  \n",
      "0  [0, 3, 7, 6, 1, 10, 8, 5, 2, 9, 4, 0]  \n",
      "1         [0, 5, 3, 4, 6, 8, 2, 1, 7, 0]  \n",
      "2            [0, 2, 3, 5, 7, 1, 4, 6, 0]  \n",
      "3            [0, 6, 7, 3, 1, 5, 4, 2, 0]  \n",
      "4      [0, 6, 2, 7, 8, 5, 9, 4, 1, 3, 0]  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def held_karp(dists):\n",
    "    n = len(dists)\n",
    "    C = {}\n",
    "    for k in range(1, n):\n",
    "        C[(1 << k, k)] = (dists[0][k], 0)\n",
    "    for subset_size in range(2, n):\n",
    "        for subset in itertools.combinations(range(1, n), subset_size):\n",
    "            bits = sum(1 << bit for bit in subset)\n",
    "            for k in subset:\n",
    "                prev = bits & ~(1 << k)\n",
    "                res = min(((C[(prev, m)][0] + dists[m][k], m) for m in subset if m != 0 and m != k),\n",
    "                          key=lambda x: x[0])\n",
    "                C[(bits, k)] = res\n",
    "    bits = (2 ** n - 1) - 1\n",
    "    opt, parent = min(((C[(bits, k)][0] + dists[k][0], k) for k in range(1, n)),\n",
    "                       key=lambda x: x[0])\n",
    "    path = [0]\n",
    "    for i in range(n - 1):\n",
    "        path.append(parent)\n",
    "        new_bits = bits & ~(1 << parent)\n",
    "        _, parent = C[(bits, parent)]\n",
    "        bits = new_bits\n",
    "    path.append(0)\n",
    "    return opt, list(reversed(path))\n",
    "\n",
    "def generate_distances(n):\n",
    "    dists = [[0 if i == j else random.randint(1, 99) for j in range(n)] for i in range(n)]\n",
    "    return dists\n",
    "\n",
    "# Génération des graphes et solutions TSP\n",
    "def generate_tsp_solutions(n_graphs=800):\n",
    "    X = []\n",
    "    y = []\n",
    "    for _ in range(n_graphs):\n",
    "        n = random.randint(8, 15)  # Taille du graphe\n",
    "        dists = generate_distances(n)  # Génération de la matrice de distances\n",
    "        opt, path = held_karp(dists)  # Calcul de la solution optimale\n",
    "        X.append(np.array(dists).flatten())  # Matrice de distance aplatie\n",
    "        y.append(path)  # Chemin optimal\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_tsp_solutions()\n",
    "\n",
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Feature_X': X,\n",
    "    'Target_y': y\n",
    "})\n",
    "\n",
    "# Affichage des premières lignes pour vérifier\n",
    "print(df.head())\n",
    "\n",
    "# Enregistrement optionnel\n",
    "# df.to_csv('tsp_solutions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 shortest paths found\n",
      "20 shortest paths found\n",
      "30 shortest paths found\n",
      "40 shortest paths found\n",
      "50 shortest paths found\n",
      "60 shortest paths found\n",
      "70 shortest paths found\n",
      "80 shortest paths found\n",
      "90 shortest paths found\n",
      "100 shortest paths found\n",
      "110 shortest paths found\n",
      "120 shortest paths found\n",
      "130 shortest paths found\n",
      "140 shortest paths found\n",
      "150 shortest paths found\n",
      "160 shortest paths found\n",
      "170 shortest paths found\n",
      "180 shortest paths found\n",
      "190 shortest paths found\n",
      "200 shortest paths found\n",
      "210 shortest paths found\n",
      "220 shortest paths found\n",
      "230 shortest paths found\n",
      "240 shortest paths found\n",
      "250 shortest paths found\n",
      "260 shortest paths found\n",
      "270 shortest paths found\n",
      "280 shortest paths found\n",
      "290 shortest paths found\n",
      "300 shortest paths found\n",
      "310 shortest paths found\n",
      "320 shortest paths found\n",
      "330 shortest paths found\n",
      "340 shortest paths found\n",
      "350 shortest paths found\n",
      "360 shortest paths found\n",
      "370 shortest paths found\n",
      "380 shortest paths found\n",
      "390 shortest paths found\n",
      "400 shortest paths found\n",
      "410 shortest paths found\n",
      "420 shortest paths found\n",
      "430 shortest paths found\n",
      "440 shortest paths found\n",
      "450 shortest paths found\n",
      "460 shortest paths found\n",
      "470 shortest paths found\n",
      "480 shortest paths found\n",
      "490 shortest paths found\n",
      "500 shortest paths found\n",
      "510 shortest paths found\n",
      "520 shortest paths found\n",
      "530 shortest paths found\n",
      "540 shortest paths found\n",
      "550 shortest paths found\n",
      "560 shortest paths found\n",
      "570 shortest paths found\n",
      "580 shortest paths found\n",
      "590 shortest paths found\n",
      "600 shortest paths found\n",
      "610 shortest paths found\n",
      "620 shortest paths found\n",
      "630 shortest paths found\n",
      "640 shortest paths found\n",
      "650 shortest paths found\n",
      "660 shortest paths found\n",
      "670 shortest paths found\n",
      "680 shortest paths found\n",
      "690 shortest paths found\n",
      "700 shortest paths found\n",
      "710 shortest paths found\n",
      "720 shortest paths found\n",
      "730 shortest paths found\n",
      "740 shortest paths found\n",
      "750 shortest paths found\n",
      "760 shortest paths found\n",
      "770 shortest paths found\n",
      "780 shortest paths found\n",
      "790 shortest paths found\n",
      "800 shortest paths found\n",
      "                                           Feature_X  \\\n",
      "0  [0, 76, 52, 39, 51, 45, 34, 63, 65, 0, 36, 29,...   \n",
      "1  [0, 23, 46, 17, 39, 43, 97, 8, 91, 35, 70, 2, ...   \n",
      "2  [0, 28, 91, 79, 47, 93, 30, 46, 93, 0, 9, 88, ...   \n",
      "3  [0, 72, 89, 99, 52, 21, 46, 80, 76, 17, 94, 49...   \n",
      "4  [0, 85, 46, 11, 86, 87, 11, 74, 82, 75, 80, 72...   \n",
      "\n",
      "                                            Target_y  \n",
      "0                        [0, 3, 1, 7, 2, 5, 6, 4, 0]  \n",
      "1              [0, 1, 6, 8, 9, 7, 5, 2, 4, 3, 10, 0]  \n",
      "2                        [0, 7, 1, 2, 5, 3, 6, 4, 0]  \n",
      "3  [0, 5, 13, 6, 9, 11, 7, 4, 10, 1, 2, 12, 8, 3, 0]  \n",
      "4  [0, 3, 9, 5, 13, 4, 7, 2, 12, 6, 11, 8, 1, 10, 0]  \n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def held_karp(dists):\n",
    "    n = len(dists)\n",
    "    C = {}\n",
    "    for k in range(1, n):\n",
    "        C[(1 << k, k)] = (dists[0][k], 0)\n",
    "    for subset_size in range(2, n):\n",
    "        for subset in itertools.combinations(range(1, n), subset_size):\n",
    "            bits = sum(1 << bit for bit in subset)\n",
    "            for k in subset:\n",
    "                prev = bits & ~(1 << k)\n",
    "                res = min(((C[(prev, m)][0] + dists[m][k], m) for m in subset if m != 0 and m != k),\n",
    "                          key=lambda x: x[0])\n",
    "                C[(bits, k)] = res\n",
    "    bits = (2 ** n - 1) - 1\n",
    "    opt, parent = min(((C[(bits, k)][0] + dists[k][0], k) for k in range(1, n)),\n",
    "                       key=lambda x: x[0])\n",
    "    path = [0]\n",
    "    for i in range(n - 1):\n",
    "        path.append(parent)\n",
    "        new_bits = bits & ~(1 << parent)\n",
    "        _, parent = C[(bits, parent)]\n",
    "        bits = new_bits\n",
    "    path.append(0)\n",
    "    return opt, list(reversed(path))\n",
    "\n",
    "def generate_distances(n):\n",
    "    dists = [[0 if i == j else random.randint(1, 99) for j in range(n)] for i in range(n)]\n",
    "    return dists\n",
    "\n",
    "def generate_tsp_solutions(n_graphs=800):\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(n_graphs):\n",
    "        n = random.randint(8, 15)  # Taille du graphe\n",
    "        dists = generate_distances(n)  # Génération de la matrice de distances\n",
    "        opt, path = held_karp(dists)  # Calcul de la solution optimale\n",
    "        X.append(np.array(dists).flatten())  # Matrice de distance aplatie\n",
    "        y.append(path)  # Chemin optimal\n",
    "        \n",
    "        # Afficher un message d'état toutes les 10 itérations\n",
    "        if (i + 1) % 10 == 0:\n",
    "            print(f\"{i + 1} shortest paths found\")\n",
    "    return X, y\n",
    "\n",
    "X, y = generate_tsp_solutions()\n",
    "\n",
    "# Conversion en DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Feature_X': X,\n",
    "    'Target_y': y\n",
    "})\n",
    "\n",
    "# Affichage des premières lignes pour vérifier\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Incohérence détectée dans les longueurs des vecteurs.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 13\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Normalisation des caractéristiques d'entrée.\u001b[39;00m\n\u001b[0;32m     12\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m---> 13\u001b[0m X_normalized \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Les données `X_normalized` sont maintenant prêtes à être utilisées comme entrées du modèle.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\base.py:916\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    915\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 916\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    917\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:435\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    433\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[0;32m    434\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[1;32m--> 435\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\base.py:1152\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1147\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1148\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1149\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1150\u001b[0m     )\n\u001b[0;32m   1151\u001b[0m ):\n\u001b[1;32m-> 1152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\preprocessing\\_data.py:473\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    467\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    468\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    469\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    470\u001b[0m     )\n\u001b[0;32m    472\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 473\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    474\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    480\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m    481\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\base.py:605\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    603\u001b[0m         out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    604\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 605\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mX\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    606\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[0;32m    607\u001b[0m     out \u001b[38;5;241m=\u001b[39m _check_y(y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\utils\\validation.py:915\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    913\u001b[0m         array \u001b[38;5;241m=\u001b[39m xp\u001b[38;5;241m.\u001b[39mastype(array, dtype, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 915\u001b[0m         array \u001b[38;5;241m=\u001b[39m \u001b[43m_asarray_with_order\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mxp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mxp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    918\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mComplex data not supported\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(array)\n\u001b[0;32m    919\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcomplex_warning\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\emac\\Documents\\dl_graph\\graphdl_env\\lib\\site-packages\\sklearn\\utils\\_array_api.py:380\u001b[0m, in \u001b[0;36m_asarray_with_order\u001b[1;34m(array, dtype, order, copy, xp)\u001b[0m\n\u001b[0;32m    378\u001b[0m     array \u001b[38;5;241m=\u001b[39m numpy\u001b[38;5;241m.\u001b[39marray(array, order\u001b[38;5;241m=\u001b[39morder, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m    379\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 380\u001b[0m     array \u001b[38;5;241m=\u001b[39m \u001b[43mnumpy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[0;32m    383\u001b[0m \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n\u001b[0;32m    384\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m xp\u001b[38;5;241m.\u001b[39masarray(array)\n",
      "\u001b[1;31mValueError\u001b[0m: setting an array element with a sequence."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "max_length = max(len(x) for x in X)\n",
    "\n",
    "# Pad les vecteurs avec des zéros pour qu'ils aient tous la même longueur\n",
    "X_padded = np.array([xi + [0]*(max_length - len(xi)) for xi in X])\n",
    "\n",
    "# Maintenant, X_padded est prêt pour le MinMaxScaler et le modèle de deep learning\n",
    "scaler = MinMaxScaler()\n",
    "X_normalized = scaler.fit_transform(X_padded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 15 is out of bounds for axis 1 with size 15",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 11\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;66;03m# Détermination du nombre de nœuds maximum pour le one-hot encoding.\u001b[39;00m\n\u001b[0;32m     10\u001b[0m n_nodes_max \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mmax\u001b[39m(path) \u001b[38;5;28;01mfor\u001b[39;00m path \u001b[38;5;129;01min\u001b[39;00m y) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m---> 11\u001b[0m y_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mencode_paths\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_nodes_max\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;66;03m# `y_encoded` est maintenant prêt à être utilisé comme cible du modèle.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36mencode_paths\u001b[1;34m(paths, n_nodes)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j, node \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(path):\n\u001b[0;32m      5\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m node \u001b[38;5;241m<\u001b[39m n_nodes:  \u001b[38;5;66;03m# Assurez-vous que le noeud est dans la plage.\u001b[39;00m\n\u001b[1;32m----> 6\u001b[0m             \u001b[43mencoded_paths\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m encoded_paths\n",
      "\u001b[1;31mIndexError\u001b[0m: index 15 is out of bounds for axis 1 with size 15"
     ]
    }
   ],
   "source": [
    "def encode_paths(paths, n_nodes):\n",
    "    encoded_paths = np.zeros((len(paths), n_nodes, n_nodes), dtype=int)\n",
    "    for i, path in enumerate(paths):\n",
    "        for j, node in enumerate(path):\n",
    "            if node < n_nodes:  # Assurez-vous que le noeud est dans la plage.\n",
    "                encoded_paths[i, j, node] = 1\n",
    "    return encoded_paths\n",
    "\n",
    "# Détermination du nombre de nœuds maximum pour le one-hot encoding.\n",
    "n_nodes_max = max(max(path) for path in y) + 1\n",
    "y_encoded = encode_paths(y, n_nodes_max)\n",
    "\n",
    "# `y_encoded` est maintenant prêt à être utilisé comme cible du modèle.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "graphdl_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
